diff --git a/reproduce_kmeans.py b/reproduce_kmeans.py
new file mode 100644
index 000000000..9d649f5c3
--- /dev/null
+++ b/reproduce_kmeans.py
@@ -0,0 +1,15 @@
+from sklearn.cluster import KMeans
+from sklearn.datasets import make_blobs
+import numpy as np
+
+# For reproducibility
+np.random.seed(2)
+
+# Generate some data
+X, y = make_blobs(n_samples=10000, centers=10, n_features=2, random_state=2)
+
+# Run KMeans with various n_jobs values
+for n_jobs in range(1, 5):
+    kmeans = KMeans(n_clusters=10, random_state=2, n_jobs=n_jobs)
+    kmeans.fit(X)
+    print(f'(n_jobs={n_jobs}) kmeans.inertia_ = {kmeans.inertia_}')
\ No newline at end of file
diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py
index b7fbdf7da..d58e100e8 100644
--- a/sklearn/cluster/k_means_.py
+++ b/sklearn/cluster/k_means_.py
@@ -360,16 +360,20 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',
     else:
         raise ValueError("Algorithm must be 'auto', 'full' or 'elkan', got"
                          " %s" % str(algorithm))
+    # Generate seeds for all initializations to ensure consistency between
+    # parallel and non-parallel runs
+    seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)
+    
     if effective_n_jobs(n_jobs) == 1:
         # For a single thread, less memory is needed if we just store one set
         # of the best results (as opposed to one set per run per thread).
-        for it in range(n_init):
+        for it, seed in enumerate(seeds):
             # run a k-means once
             labels, inertia, centers, n_iter_ = kmeans_single(
                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,
                 verbose=verbose, precompute_distances=precompute_distances,
                 tol=tol, x_squared_norms=x_squared_norms,
-                random_state=random_state)
+                random_state=seed)
             # determine if these results are the best so far
             if best_inertia is None or inertia < best_inertia:
                 best_labels = labels.copy()
@@ -378,7 +382,6 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',
                 best_n_iter = n_iter_
     else:
         # parallelisation of k-means runs
-        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)
         results = Parallel(n_jobs=n_jobs, verbose=0)(
             delayed(kmeans_single)(X, sample_weight, n_clusters,
                                    max_iter=max_iter, init=init,
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 000000000..201a6f56a
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,34 @@
+from sklearn.cluster import KMeans
+from sklearn.datasets import make_blobs
+import numpy as np
+
+# For reproducibility
+np.random.seed(2)
+
+# Generate some data
+X, y = make_blobs(n_samples=10000, centers=10, n_features=2, random_state=2)
+
+print("Test case 1: n_init=1")
+for n_jobs in range(1, 5):
+    kmeans = KMeans(n_clusters=10, random_state=2, n_jobs=n_jobs, n_init=1)
+    kmeans.fit(X)
+    print(f'(n_jobs={n_jobs}) kmeans.inertia_ = {kmeans.inertia_}')
+
+print("\nTest case 2: Explicit init array")
+# Test with explicit init array
+init_centers = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5], 
+                        [6, 6], [7, 7], [8, 8], [9, 9], [10, 10]])
+for n_jobs in range(1, 5):
+    kmeans = KMeans(n_clusters=10, random_state=2, n_jobs=n_jobs, init=init_centers)
+    kmeans.fit(X)
+    print(f'(n_jobs={n_jobs}) kmeans.inertia_ = {kmeans.inertia_}')
+
+print("\nTest case 3: Different random states")
+# Test with different random states
+for random_state in range(5):
+    inertias = []
+    for n_jobs in range(1, 5):
+        kmeans = KMeans(n_clusters=10, random_state=random_state, n_jobs=n_jobs)
+        kmeans.fit(X)
+        inertias.append(kmeans.inertia_)
+    print(f'random_state={random_state}, all equal: {len(set(inertias)) == 1}')
\ No newline at end of file
