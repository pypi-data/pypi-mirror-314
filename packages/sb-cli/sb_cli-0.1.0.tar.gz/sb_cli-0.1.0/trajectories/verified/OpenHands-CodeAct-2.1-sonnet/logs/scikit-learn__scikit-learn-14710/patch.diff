diff --git a/reproduce_error.py b/reproduce_error.py
new file mode 100644
index 000000000..c6dc14aed
--- /dev/null
+++ b/reproduce_error.py
@@ -0,0 +1,13 @@
+import numpy as np
+from sklearn.experimental import enable_hist_gradient_boosting  # noqa
+from sklearn.ensemble import HistGradientBoostingClassifier
+
+# Create sample data
+X = np.random.randn(100, 10)
+y = np.array(['x'] * 50 + ['y'] * 50, dtype=object)
+
+# Create classifier with early stopping
+gbrt = HistGradientBoostingClassifier(n_iter_no_change=10)
+
+# Try to fit the model
+gbrt.fit(X, y)
\ No newline at end of file
diff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py
index ad6a5a8ca..b122d1b9d 100644
--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py
+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py
@@ -426,11 +426,17 @@ class BaseHistGradientBoosting(BaseEstimator, ABC):
 
         Scores are computed on validation data or on training data.
         """
+        # Convert integer-encoded labels back to original string labels for scoring
+        if hasattr(self, 'classes_'):
+            y_small_train = self.classes_[y_small_train.astype(int)]
+
         self.train_score_.append(
             self.scorer_(self, X_binned_small_train, y_small_train)
         )
 
         if self._use_validation_data:
+            if hasattr(self, 'classes_'):
+                y_val = self.classes_[y_val.astype(int)]
             self.validation_score_.append(
                 self.scorer_(self, X_binned_val, y_val)
             )
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 000000000..e5ee20256
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,31 @@
+import numpy as np
+from sklearn.experimental import enable_hist_gradient_boosting  # noqa
+from sklearn.ensemble import HistGradientBoostingClassifier
+
+# Test case 1: Mix of string and numeric labels
+X = np.random.randn(100, 10)
+y = np.array(['x'] * 33 + ['1'] * 33 + ['y'] * 34, dtype=object)
+gbrt = HistGradientBoostingClassifier(n_iter_no_change=10)
+print("Test case 1: Mix of string and numeric labels")
+gbrt.fit(X, y)
+print("Predicted classes:", gbrt.predict(X[:5]))
+print("Score:", gbrt.score(X, y))
+
+# Test case 2: Single class (edge case)
+X = np.random.randn(100, 10)
+y = np.array(['same_label'] * 100, dtype=object)
+gbrt = HistGradientBoostingClassifier(n_iter_no_change=10)
+print("\nTest case 2: Single class")
+try:
+    gbrt.fit(X, y)
+except Exception as e:
+    print("Expected error for single class:", str(e))
+
+# Test case 3: Empty strings
+X = np.random.randn(100, 10)
+y = np.array([''] * 50 + ['non_empty'] * 50, dtype=object)
+gbrt = HistGradientBoostingClassifier(n_iter_no_change=10)
+print("\nTest case 3: Empty strings")
+gbrt.fit(X, y)
+print("Predicted classes:", gbrt.predict(X[:5]))
+print("Score:", gbrt.score(X, y))
\ No newline at end of file
