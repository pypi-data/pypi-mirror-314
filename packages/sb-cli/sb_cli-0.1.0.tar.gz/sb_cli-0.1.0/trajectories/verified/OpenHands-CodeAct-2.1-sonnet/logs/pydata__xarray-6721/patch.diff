diff --git a/reproduce_chunks_issue.py b/reproduce_chunks_issue.py
new file mode 100644
index 00000000..5e76f661
--- /dev/null
+++ b/reproduce_chunks_issue.py
@@ -0,0 +1,8 @@
+import xarray as xr
+
+url = "https://ncsa.osn.xsede.org/Pangeo/pangeo-forge/swot_adac/FESOM/surf/fma.zarr"
+ds = xr.open_dataset(url, engine='zarr')  # note that ds is not chunked but still uses lazy loading
+print("Dataset opened successfully")
+print("Accessing chunks attribute...")
+print(ds.chunks)
+print("Chunks accessed successfully")
\ No newline at end of file
diff --git a/reproduce_chunks_issue_chunked.py b/reproduce_chunks_issue_chunked.py
new file mode 100644
index 00000000..a7c87c6e
--- /dev/null
+++ b/reproduce_chunks_issue_chunked.py
@@ -0,0 +1,10 @@
+import xarray as xr
+import numpy as np
+
+# Create a chunked dataset
+data = np.random.randn(1000, 1000)
+ds = xr.Dataset({"data": (["x", "y"], data)}).chunk({"x": 100, "y": 100})
+print("Dataset created successfully")
+print("Accessing chunks attribute...")
+print(ds.chunks)
+print("Chunks accessed successfully")
\ No newline at end of file
diff --git a/xarray/core/common.py b/xarray/core/common.py
index 3c328f42..56592aa5 100644
--- a/xarray/core/common.py
+++ b/xarray/core/common.py
@@ -2023,7 +2023,8 @@ def get_chunksizes(
 
     chunks: dict[Any, tuple[int, ...]] = {}
     for v in variables:
-        if hasattr(v.data, "chunks"):
+        # Check for chunks on the raw data object to avoid loading
+        if hasattr(v._data, "chunks"):
             for dim, c in v.chunksizes.items():
                 if dim in chunks and c != chunks[dim]:
                     raise ValueError(
