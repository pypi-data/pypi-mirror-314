diff --git a/reproduce.py b/reproduce.py
new file mode 100644
index 000000000..4d966dc9b
--- /dev/null
+++ b/reproduce.py
@@ -0,0 +1,39 @@
+import numpy as np
+from sklearn.experimental import enable_iterative_imputer  # noqa
+from sklearn.impute import IterativeImputer, SimpleImputer
+from sklearn.ensemble import HistGradientBoostingRegressor
+
+# Create sample data with missing values
+X = np.array([[1, 2, np.nan], 
+              [4, np.nan, 6], 
+              [7, 8, 9]])
+
+# Show that SimpleImputer supports fill_value with constant strategy
+print("SimpleImputer with constant strategy and fill_value=99:")
+imp_simple = SimpleImputer(strategy="constant", fill_value=99)
+print(imp_simple.fit_transform(X))
+print()
+
+# Show that IterativeImputer now supports fill_value with initial_strategy="constant"
+print("IterativeImputer with initial_strategy='constant' and fill_value=99:")
+imp_iter = IterativeImputer(initial_strategy="constant", fill_value=99)
+print(imp_iter.fit_transform(X))
+print()
+
+# Test with np.nan as fill_value and default estimator (should raise error)
+print("Testing IterativeImputer with fill_value=np.nan and default estimator (should fail):")
+try:
+    imp_iter_nan = IterativeImputer(initial_strategy="constant", fill_value=np.nan)
+    imp_iter_nan.fit_transform(X)
+except ValueError as e:
+    print("Got expected error:", str(e))
+print()
+
+# Test with np.nan as fill_value and tree-based estimator (should work)
+print("IterativeImputer with initial_strategy='constant', fill_value=np.nan and tree-based estimator:")
+imp_iter_nan = IterativeImputer(
+    estimator=HistGradientBoostingRegressor(),  # This estimator supports NaN natively
+    initial_strategy="constant",
+    fill_value=np.nan
+)
+print(imp_iter_nan.fit_transform(X))
\ No newline at end of file
diff --git a/sklearn/impute/_iterative.py b/sklearn/impute/_iterative.py
index 1d918bc0c..f1e41c37b 100644
--- a/sklearn/impute/_iterative.py
+++ b/sklearn/impute/_iterative.py
@@ -117,6 +117,13 @@ class IterativeImputer(_BaseImputer):
         Which strategy to use to initialize the missing values. Same as the
         `strategy` parameter in :class:`~sklearn.impute.SimpleImputer`.
 
+    fill_value : str or numerical value, default=None
+        When initial_strategy="constant", fill_value is used to replace all
+        occurrences of missing_values. For string or object data types,
+        fill_value must be a string. If None, fill_value will be 0 when
+        imputing numerical data and "missing_value" for strings or object
+        data types.
+
     imputation_order : {'ascending', 'descending', 'roman', 'arabic', \
             'random'}, default='ascending'
         The order in which the features will be imputed. Possible values:
@@ -281,6 +288,7 @@ class IterativeImputer(_BaseImputer):
         "initial_strategy": [
             StrOptions({"mean", "median", "most_frequent", "constant"})
         ],
+        "fill_value": "no_validation",  # any object is valid, same as SimpleImputer
         "imputation_order": [
             StrOptions({"ascending", "descending", "roman", "arabic", "random"})
         ],
@@ -301,6 +309,7 @@ class IterativeImputer(_BaseImputer):
         tol=1e-3,
         n_nearest_features=None,
         initial_strategy="mean",
+        fill_value=None,
         imputation_order="ascending",
         skip_complete=False,
         min_value=-np.inf,
@@ -322,6 +331,7 @@ class IterativeImputer(_BaseImputer):
         self.tol = tol
         self.n_nearest_features = n_nearest_features
         self.initial_strategy = initial_strategy
+        self.fill_value = fill_value
         self.imputation_order = imputation_order
         self.skip_complete = skip_complete
         self.min_value = min_value
@@ -610,9 +620,26 @@ class IterativeImputer(_BaseImputer):
         X_missing_mask = _get_mask(X, self.missing_values)
         mask_missing_values = X_missing_mask.copy()
         if self.initial_imputer_ is None:
+            # Special case: if initial_strategy is 'constant' and fill_value is np.nan,
+            # we need to validate that the estimator supports NaN values
+            if (self.initial_strategy == "constant" and 
+                self.fill_value is not None and 
+                is_scalar_nan(self.fill_value)):
+                # Check if estimator supports NaN values
+                if not hasattr(self._estimator, "_get_tags") or not self._estimator._get_tags().get("allow_nan", False):
+                    raise ValueError(
+                        "When using fill_value=np.nan with initial_strategy='constant', "
+                        "the estimator must support NaN values. The current estimator "
+                        f"({self._estimator.__class__.__name__}) does not support NaN values. "
+                        "Consider using a tree-based estimator like HistGradientBoostingRegressor "
+                        "which supports NaN values natively."
+                    )
+
+            # Initialize the imputer
             self.initial_imputer_ = SimpleImputer(
                 missing_values=self.missing_values,
                 strategy=self.initial_strategy,
+                fill_value=self.fill_value,
                 keep_empty_features=self.keep_empty_features,
             )
             X_filled = self.initial_imputer_.fit_transform(X)
