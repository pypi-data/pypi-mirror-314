diff --git a/reproduce_error.py b/reproduce_error.py
new file mode 100644
index 000000000..83a417114
--- /dev/null
+++ b/reproduce_error.py
@@ -0,0 +1,24 @@
+from sklearn.datasets import make_classification
+from sklearn.feature_selection import SequentialFeatureSelector
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.model_selection import LeaveOneGroupOut
+
+import numpy as np
+
+# Create sample data
+X, y = make_classification()
+
+# Create groups for cross-validation
+groups = np.zeros_like(y, dtype=int)
+groups[y.size//2:] = 1
+
+# Create cross-validator and get splits
+cv = LeaveOneGroupOut()
+splits = cv.split(X, y, groups=groups)
+
+# Create classifier and sequential selector
+clf = KNeighborsClassifier(n_neighbors=5)
+seq = SequentialFeatureSelector(clf, n_features_to_select=5, scoring='accuracy', cv=splits)
+
+# Try to fit
+seq.fit(X, y)
\ No newline at end of file
diff --git a/sklearn/feature_selection/_sequential.py b/sklearn/feature_selection/_sequential.py
index e983c55de..a82d06dd2 100644
--- a/sklearn/feature_selection/_sequential.py
+++ b/sklearn/feature_selection/_sequential.py
@@ -305,14 +305,26 @@ class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator
             if self.direction == "backward":
                 candidate_mask = ~candidate_mask
             X_new = X[:, candidate_mask]
-            scores[feature_idx] = cross_val_score(
-                estimator,
-                X_new,
-                y,
-                cv=self.cv,
-                scoring=self.scoring,
-                n_jobs=self.n_jobs,
-            ).mean()
+            try:
+                cv_scores = cross_val_score(
+                    estimator,
+                    X_new,
+                    y,
+                    cv=self.cv,
+                    scoring=self.scoring,
+                    n_jobs=self.n_jobs,
+                )
+                # If no valid scores (e.g. no valid splits), use NaN
+                scores[feature_idx] = np.nan if len(cv_scores) == 0 else cv_scores.mean()
+            except ValueError as e:
+                # Handle cases where CV splitter raises error (e.g. LeaveOneGroupOut with <2 groups)
+                scores[feature_idx] = np.nan
+        
+        # If all scores are NaN, select the first feature
+        if all(np.isnan(list(scores.values()))):
+            new_feature_idx = candidate_feature_indices[0]
+            return new_feature_idx, np.nan
+            
         new_feature_idx = max(scores, key=lambda feature_idx: scores[feature_idx])
         return new_feature_idx, scores[new_feature_idx]
 
diff --git a/sklearn/model_selection/_validation.py b/sklearn/model_selection/_validation.py
index 8bd044bbd..f394e31b5 100644
--- a/sklearn/model_selection/_validation.py
+++ b/sklearn/model_selection/_validation.py
@@ -309,6 +309,20 @@ def cross_validate(
     results = _aggregate_score_dicts(results)
 
     ret = {}
+    
+    # Handle empty results case
+    if not results:
+        ret["fit_time"] = np.array([])
+        ret["score_time"] = np.array([])
+        if return_estimator:
+            ret["estimator"] = []
+        if return_indices:
+            ret["indices"] = {"train": [], "test": []}
+        ret["test_score"] = np.array([])
+        if return_train_score:
+            ret["train_score"] = np.array([])
+        return ret
+
     ret["fit_time"] = results["fit_time"]
     ret["score_time"] = results["score_time"]
 
@@ -1943,6 +1957,8 @@ def _aggregate_score_dicts(scores):
     {'a': array([1, 2, 3, 10]),
      'b': array([10, 2, 3, 10])}
     """
+    if not scores:
+        return {}
     return {
         key: np.asarray([score[key] for score in scores])
         if isinstance(scores[0][key], numbers.Number)
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 000000000..3a457dec5
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,50 @@
+from sklearn.datasets import make_classification
+from sklearn.feature_selection import SequentialFeatureSelector
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.model_selection import LeaveOneGroupOut, GroupKFold, PredefinedSplit
+import numpy as np
+
+# Test 1: LeaveOneGroupOut with no valid splits
+print("Test 1: LeaveOneGroupOut with no valid splits")
+X, y = make_classification(n_samples=10, n_features=5)
+groups = np.zeros_like(y, dtype=int)  # All samples in same group
+cv = LeaveOneGroupOut()
+splits = cv.split(X, y, groups=groups)
+clf = KNeighborsClassifier(n_neighbors=3)
+seq = SequentialFeatureSelector(clf, n_features_to_select=2, cv=splits)
+seq.fit(X, y)
+print("Selected features:", np.where(seq.support_)[0])
+
+# Test 2: PredefinedSplit with no test fold
+print("\nTest 2: PredefinedSplit with no test fold")
+test_fold = np.full(y.shape, -1)  # No test fold
+cv = PredefinedSplit(test_fold)
+splits = cv.split(X, y)
+seq = SequentialFeatureSelector(clf, n_features_to_select=2, cv=splits)
+seq.fit(X, y)
+print("Selected features:", np.where(seq.support_)[0])
+
+# Test 3: GroupKFold with single group
+print("\nTest 3: GroupKFold with single group")
+cv = GroupKFold(n_splits=2)
+splits = cv.split(X, y, groups=groups)
+seq = SequentialFeatureSelector(clf, n_features_to_select=2, cv=splits)
+seq.fit(X, y)
+print("Selected features:", np.where(seq.support_)[0])
+
+# Test 4: Empty feature matrix
+print("\nTest 4: Empty feature matrix")
+X_empty = np.array([]).reshape(10, 0)
+y_empty = np.zeros(10)
+try:
+    seq = SequentialFeatureSelector(clf, n_features_to_select=2)
+    seq.fit(X_empty, y_empty)
+except Exception as e:
+    print("Expected error:", str(e))
+
+# Test 5: Single feature
+print("\nTest 5: Single feature")
+X_single = X[:, :1]
+seq = SequentialFeatureSelector(clf, n_features_to_select=1)
+seq.fit(X_single, y)
+print("Selected features:", np.where(seq.support_)[0])
\ No newline at end of file
