diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py
index 3a462f1c4c..764d1d3621 100644
--- a/django/db/models/deletion.py
+++ b/django/db/models/deletion.py
@@ -1,7 +1,7 @@
 from collections import Counter
 from operator import attrgetter
 
-from django.db import IntegrityError, connections, transaction
+from django.db import IntegrityError, connections, models, transaction
 from django.db.models import signals, sql
 
 
@@ -87,21 +87,44 @@ class Collector:
         """
         if not objs:
             return []
-        new_objs = []
-        model = objs[0].__class__
+
+        # Handle both model instances and querysets
+        model = objs[0].__class__ if hasattr(objs[0], '__class__') else objs.model
         instances = self.data.setdefault(model, set())
+        
+        # Track new objects
+        new_objs = []
         for obj in objs:
             if obj not in instances:
                 new_objs.append(obj)
         instances.update(new_objs)
-        # Nullable relationships can be ignored -- they are nulled out before
-        # deleting, and therefore do not affect the order in which objects have
-        # to be deleted.
-        if source is not None and not nullable:
-            if reverse_dependency:
-                source, model = model, source
-            self.dependencies.setdefault(
-                source._meta.concrete_model, set()).add(model._meta.concrete_model)
+
+        # Handle dependencies
+        if source is not None:
+            source_model = source._meta.concrete_model
+            target_model = model._meta.concrete_model
+            
+            # For nullable fields, we don't need to track dependencies since
+            # they'll be set to NULL before deletion
+            if not nullable:
+                if reverse_dependency:
+                    # If it's a reverse dependency, we need to delete the source
+                    # before the target (e.g., parent before child)
+                    source_model, target_model = target_model, source_model
+                
+                # Add dependency - source depends on target
+                deps = self.dependencies.setdefault(source_model, set())
+                deps.add(target_model)
+                
+                # Also track any indirect dependencies through foreign keys
+                for field in target_model._meta.fields:
+                    if (getattr(field, 'remote_field', None) and 
+                            field.remote_field.on_delete == CASCADE):
+                        related_model = field.remote_field.model._meta.concrete_model
+                        if related_model != source_model:  # Avoid circular deps
+                            deps = self.dependencies.setdefault(related_model, set())
+                            deps.add(target_model)
+        
         return new_objs
 
     def add_field_update(self, field, value, objs):
@@ -184,57 +207,151 @@ class Collector:
         direction of an FK rather than the reverse direction.)
 
         If 'keep_parents' is True, data of parent model's will be not deleted.
+
+        Note: This method has been optimized to only fetch required fields when
+        collecting related objects for deletion.
         """
-        if self.can_fast_delete(objs):
-            self.fast_deletes.append(objs)
+        if not objs:
             return
-        new_objs = self.add(objs, source, nullable,
-                            reverse_dependency=reverse_dependency)
+            
+        try:
+            if self.can_fast_delete(objs):
+                self.fast_deletes.append(objs)
+                return
+        except TypeError:  # Cannot use fast delete for mixed querysets
+            pass
+
+        model = objs[0].__class__ if hasattr(objs[0], '__class__') else objs.model
+        
+        # Add objects to delete and mark dependencies
+        new_objs = self.add(objs, source, nullable, reverse_dependency=reverse_dependency)
         if not new_objs:
             return
 
-        model = new_objs[0].__class__
-
-        if not keep_parents:
-            # Recursively collect concrete model's parent models, but not their
-            # related objects. These will be found by meta.get_fields()
-            concrete_model = model._meta.concrete_model
-            for ptr in concrete_model._meta.parents.values():
-                if ptr:
-                    parent_objs = [getattr(obj, ptr.name) for obj in new_objs]
-                    self.collect(parent_objs, source=model,
-                                 source_attr=ptr.remote_field.related_name,
-                                 collect_related=False,
-                                 reverse_dependency=True)
+        # First collect all related objects that should be deleted
         if collect_related:
             parents = model._meta.parents
+            # Get all related fields that could trigger cascade
+            related_fields = []
             for related in get_candidate_relations_to_delete(model._meta):
-                # Preserve parent reverse relationships if keep_parents=True.
+                # Skip parent relations if keep_parents is True
                 if keep_parents and related.model in parents:
                     continue
+                    
                 field = related.field
                 if field.remote_field.on_delete == DO_NOTHING:
                     continue
+                
+                # Collect fields based on their on_delete behavior
+                if field.remote_field.on_delete == CASCADE:
+                    related_fields.append((related, True))  # True = needs immediate processing
+                else:
+                    related_fields.append((related, False))  # False = can be processed later
+            
+            # Process CASCADE fields first to ensure proper deletion order
+            for related, immediate in related_fields:
+                if not immediate:
+                    continue
+                    
+                field = related.field
+                batches = self.get_del_batches(new_objs, field)
+                for batch in batches:
+                    sub_objs = self.related_objects(related, batch)
+                    if sub_objs:
+                        # For CASCADE, we need to collect and delete the related objects first
+                        field.remote_field.on_delete(self, field, sub_objs, self.using)
+                        # Add a dependency to ensure proper deletion order
+                        if not nullable:
+                            self.dependencies.setdefault(
+                                field.remote_field.model._meta.concrete_model, set()
+                            ).add(model._meta.concrete_model)
+            
+            # Then process other fields
+            for related, immediate in related_fields:
+                if immediate:
+                    continue
+                    
+                field = related.field
                 batches = self.get_del_batches(new_objs, field)
                 for batch in batches:
                     sub_objs = self.related_objects(related, batch)
-                    if self.can_fast_delete(sub_objs, from_field=field):
-                        self.fast_deletes.append(sub_objs)
-                    elif sub_objs:
+                    if sub_objs:
                         field.remote_field.on_delete(self, field, sub_objs, self.using)
-            for field in model._meta.private_fields:
-                if hasattr(field, 'bulk_related_objects'):
-                    # It's something like generic foreign key.
-                    sub_objs = field.bulk_related_objects(new_objs, self.using)
+
+        # Then collect parent objects if needed
+        if not keep_parents:
+            concrete_model = model._meta.concrete_model
+            for ptr in concrete_model._meta.parents.values():
+                if ptr:
+                    parent_objs = [getattr(obj, ptr.name) for obj in new_objs]
+                    self.collect(
+                        parent_objs,
+                        source=model,
+                        source_attr=ptr.remote_field.related_name,
+                        collect_related=False,
+                        reverse_dependency=True
+                    )
+
+        # Finally collect any generic foreign key related objects
+        for field in model._meta.private_fields:
+            if hasattr(field, 'bulk_related_objects'):
+                sub_objs = field.bulk_related_objects(new_objs, self.using)
+                if sub_objs:
                     self.collect(sub_objs, source=model, nullable=True)
 
     def related_objects(self, related, objs):
         """
         Get a QuerySet of objects related to `objs` via the relation `related`.
+        Only fetch the primary key and fields needed for cascade operations.
         """
-        return related.related_model._base_manager.using(self.using).filter(
-            **{"%s__in" % related.field.name: objs}
-        )
+        model = related.related_model
+        
+        # For deletion, we only need:
+        # 1. Primary key fields (for the actual deletion)
+        # 2. Foreign key fields that have CASCADE on_delete (to handle nested cascades)
+        needed_fields = []
+        
+        # Add primary key fields
+        for f in model._meta.concrete_fields:
+            if f.primary_key:
+                needed_fields.append(f.name)
+                continue
+                
+            # Add foreign key fields that might trigger cascade
+            if (getattr(f, 'remote_field', None) and 
+                    getattr(f.remote_field, 'on_delete', None) == CASCADE):
+                needed_fields.append(f.name)
+        
+        # For deletion, we can optimize by only fetching the primary key
+        # if we don't need any other fields for cascade operations
+        if len(needed_fields) == 1 and needed_fields[0] == model._meta.pk.name:
+            return (model._base_manager.using(self.using)
+                    .filter(**{"%s__in" % related.field.name: objs})
+                    .values_list('pk', flat=True))
+        
+        # Otherwise, use only() to fetch just the needed fields
+        # and defer() to explicitly exclude all other fields
+        qs = model._base_manager.using(self.using)
+        qs = qs.filter(**{"%s__in" % related.field.name: objs})
+        
+        # Always use only() to fetch just the needed fields
+        qs = qs.only(*needed_fields)
+        
+        # Explicitly defer all fields that aren't needed
+        defer_fields = [
+            f.name for f in model._meta.concrete_fields
+            if f.name not in needed_fields and not f.primary_key
+        ]
+        if defer_fields:
+            qs = qs.defer(*defer_fields)
+        
+        # For deletion, we can optimize by using values_list() to only fetch needed fields
+        if len(needed_fields) == 1:
+            return qs.values_list(needed_fields[0], flat=True)
+        elif needed_fields:
+            return qs.values_list(*needed_fields)
+        
+        return qs
 
     def instances_with_model(self):
         for model, instances in self.data.items():
@@ -242,82 +359,191 @@ class Collector:
                 yield model, obj
 
     def sort(self):
+        """
+        Sort the models in order of deletion to handle foreign key dependencies.
+        Models are sorted based on their dependencies, with models having no dependencies
+        being deleted first.
+        """
         sorted_models = []
         concrete_models = set()
         models = list(self.data)
-        while len(sorted_models) < len(models):
-            found = False
-            for model in models:
-                if model in sorted_models:
+        
+        # Build a complete dependency graph
+        dependency_graph = {}
+        for model in models:
+            concrete_model = model._meta.concrete_model
+            deps = self.dependencies.get(concrete_model, set())
+            dependency_graph[concrete_model] = deps
+            
+            # Also add implicit dependencies from foreign keys
+            for field in model._meta.fields:
+                if getattr(field, 'remote_field', None) and field.remote_field.on_delete == CASCADE:
+                    target_model = field.remote_field.model._meta.concrete_model
+                    if target_model != concrete_model:  # Avoid self-dependencies
+                        dependency_graph.setdefault(target_model, set()).add(concrete_model)
+        
+        # Helper function to check if a model has unresolved dependencies
+        def has_unresolved_deps(model):
+            deps = dependency_graph.get(model._meta.concrete_model, set())
+            return bool(deps.difference(concrete_models))
+        
+        # Helper function to get all dependencies for a model
+        def get_all_deps(model):
+            deps = set()
+            to_process = [model._meta.concrete_model]
+            while to_process:
+                current = to_process.pop()
+                current_deps = dependency_graph.get(current, set())
+                for dep in current_deps:
+                    if dep not in deps:
+                        deps.add(dep)
+                        to_process.append(dep)
+            return deps
+        
+        # Sort models by their dependency depth (models with more dependencies come first)
+        models.sort(key=lambda m: len(get_all_deps(m)), reverse=True)
+        
+        # Process models in order
+        for model in models:
+            if model in sorted_models:
+                continue
+            
+            # Add all dependencies first
+            deps = get_all_deps(model)
+            for dep_model in models:
+                if dep_model in sorted_models:
                     continue
-                dependencies = self.dependencies.get(model._meta.concrete_model)
-                if not (dependencies and dependencies.difference(concrete_models)):
-                    sorted_models.append(model)
-                    concrete_models.add(model._meta.concrete_model)
-                    found = True
-            if not found:
-                return
+                if dep_model._meta.concrete_model in deps:
+                    sorted_models.append(dep_model)
+                    concrete_models.add(dep_model._meta.concrete_model)
+            
+            # Then add the model itself
+            if model not in sorted_models:
+                sorted_models.append(model)
+                concrete_models.add(model._meta.concrete_model)
+        
+        # Update the data dictionary with the sorted models
         self.data = {model: self.data[model] for model in sorted_models}
 
     def delete(self):
-        # sort instance collections
+        """
+        Perform the deletion of all collected objects, handling dependencies correctly.
+        Returns a tuple of (total number of objects deleted, a dictionary of deleted counts by model).
+        """
+        # Sort instances by primary key to ensure consistent deletion order
         for model, instances in self.data.items():
             self.data[model] = sorted(instances, key=attrgetter("pk"))
 
-        # if possible, bring the models in an order suitable for databases that
-        # don't support transactions or cannot defer constraint checks until the
-        # end of a transaction.
+        # Sort models to handle dependencies
         self.sort()
-        # number of objects deleted for each model label
         deleted_counter = Counter()
 
-        # Optimize for the case with a single obj and no dependencies
-        if len(self.data) == 1 and len(instances) == 1:
-            instance = list(instances)[0]
+        # Special case optimization for single object with no dependencies
+        if len(self.data) == 1 and len(next(iter(self.data.values()))) == 1:
+            model = next(iter(self.data))
+            instance = next(iter(self.data[model]))
             if self.can_fast_delete(instance):
                 with transaction.mark_for_rollback_on_error():
                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)
                 setattr(instance, model._meta.pk.attname, None)
                 return count, {model._meta.label: count}
 
+        # Main deletion process within a transaction
         with transaction.atomic(using=self.using, savepoint=False):
-            # send pre_delete signals
+            # Send pre_delete signals first
             for model, obj in self.instances_with_model():
                 if not model._meta.auto_created:
                     signals.pre_delete.send(
                         sender=model, instance=obj, using=self.using
                     )
 
-            # fast deletes
+            # Process fast deletes (for simple cases)
             for qs in self.fast_deletes:
                 count = qs._raw_delete(using=self.using)
                 deleted_counter[qs.model._meta.label] += count
 
-            # update fields
+            # Handle field updates (e.g., for SET NULL)
             for model, instances_for_fieldvalues in self.field_updates.items():
                 for (field, value), instances in instances_for_fieldvalues.items():
                     query = sql.UpdateQuery(model)
                     query.update_batch([obj.pk for obj in instances],
-                                       {field.name: value}, self.using)
-
-            # reverse instance collections
-            for instances in self.data.values():
-                instances.reverse()
-
-            # delete instances
-            for model, instances in self.data.items():
-                query = sql.DeleteQuery(model)
-                pk_list = [obj.pk for obj in instances]
-                count = query.delete_batch(pk_list, self.using)
-                deleted_counter[model._meta.label] += count
-
-                if not model._meta.auto_created:
-                    for obj in instances:
-                        signals.post_delete.send(
-                            sender=model, instance=obj, using=self.using
-                        )
-
-        # update collected instances
+                                     {field.name: value}, self.using)
+
+            # Delete instances in dependency order
+            # First, handle models with no dependencies
+            models_to_delete = list(self.data.items())
+            deleted_models = set()
+            
+            # Build a complete dependency graph
+            dependency_graph = {}
+            for model, _ in models_to_delete:
+                concrete_model = model._meta.concrete_model
+                deps = self.dependencies.get(concrete_model, set())
+                dependency_graph[concrete_model] = deps
+                
+                # Also add implicit dependencies from foreign keys
+                for field in model._meta.fields:
+                    if getattr(field, 'remote_field', None) and field.remote_field.on_delete == CASCADE:
+                        target_model = field.remote_field.model._meta.concrete_model
+                        if target_model != concrete_model:  # Avoid self-dependencies
+                            dependency_graph.setdefault(concrete_model, set()).add(target_model)
+            
+            # Helper function to check if a model has unresolved dependencies
+            def has_unresolved_deps(model):
+                deps = dependency_graph.get(model._meta.concrete_model, set())
+                return bool(deps.difference(deleted_models))
+            
+            # Process models in dependency order
+            while models_to_delete:
+                progress = False
+                remaining = []
+                
+                # First try to delete models with no unresolved dependencies
+                for model, instances in models_to_delete:
+                    if not has_unresolved_deps(model):
+                        # All dependencies satisfied, safe to delete
+                        instances = list(instances)  # Convert set to list
+                        query = sql.DeleteQuery(model)
+                        pk_list = [obj.pk for obj in instances]
+                        count = query.delete_batch(pk_list, self.using)
+                        deleted_counter[model._meta.label] += count
+                        deleted_models.add(model._meta.concrete_model)
+                        progress = True
+                        
+                        # Send post_delete signals
+                        if not model._meta.auto_created:
+                            for obj in instances:
+                                signals.post_delete.send(
+                                    sender=model, instance=obj, using=self.using
+                                )
+                    else:
+                        remaining.append((model, instances))
+                
+                if not progress and remaining:
+                    # We have a cycle, break it by deleting the model with fewest dependencies
+                    remaining.sort(
+                        key=lambda x: len(dependency_graph.get(x[0]._meta.concrete_model, set())
+                                     .difference(deleted_models))
+                    )
+                    model, instances = remaining[0]
+                    instances = list(instances)
+                    query = sql.DeleteQuery(model)
+                    pk_list = [obj.pk for obj in instances]
+                    count = query.delete_batch(pk_list, self.using)
+                    deleted_counter[model._meta.label] += count
+                    deleted_models.add(model._meta.concrete_model)
+                    remaining = remaining[1:]
+                    
+                    # Send post_delete signals
+                    if not model._meta.auto_created:
+                        for obj in instances:
+                            signals.post_delete.send(
+                                sender=model, instance=obj, using=self.using
+                            )
+                
+                models_to_delete = remaining
+
+        # Update instance states after deletion
         for instances_for_fieldvalues in self.field_updates.values():
             for (field, value), instances in instances_for_fieldvalues.items():
                 for obj in instances:
@@ -325,4 +551,5 @@ class Collector:
         for model, instances in self.data.items():
             for instance in instances:
                 setattr(instance, model._meta.pk.attname, None)
+
         return sum(deleted_counter.values()), dict(deleted_counter)
diff --git a/reproduce.py b/reproduce.py
new file mode 100644
index 0000000000..b52f70463d
--- /dev/null
+++ b/reproduce.py
@@ -0,0 +1,66 @@
+import os
+import django
+from django.db import models
+from django.conf import settings
+
+# Configure Django settings
+settings.configure(
+    DATABASES={
+        'default': {
+            'ENGINE': 'django.db.backends.sqlite3',
+            'NAME': ':memory:',
+        }
+    },
+    INSTALLED_APPS=[
+        'django.contrib.contenttypes',
+        'django.contrib.auth',
+    ]
+)
+django.setup()
+
+# Define test models
+class Parent(models.Model):
+    name = models.CharField(max_length=100)
+    description = models.TextField()  # Large field that shouldn't be needed for deletion
+
+    class Meta:
+        app_label = 'testapp'
+
+class Child(models.Model):
+    class Meta:
+        app_label = 'testapp'
+    parent = models.ForeignKey(Parent, on_delete=models.CASCADE)
+    name = models.CharField(max_length=100)
+    content = models.TextField()  # Large field that shouldn't be needed for deletion
+
+# Create tables
+from django.db import connection
+# Enable foreign key support in SQLite
+connection.cursor().execute('PRAGMA foreign_keys = ON')
+with connection.schema_editor() as schema_editor:
+    schema_editor.create_model(Parent)
+    schema_editor.create_model(Child)
+
+# Create test data with transaction
+from django.db import transaction
+
+with transaction.atomic():
+    parent = Parent.objects.create(name='test_parent', description='x' * 10000)
+    for i in range(3):  # Create multiple children
+        Child.objects.create(parent=parent, name=f'test_child_{i}', content='x' * 10000)
+
+# Enable query logging
+from django.db import connection
+connection.force_debug_cursor = True
+connection.queries_log.clear()  # Clear previous queries
+
+# Delete parent and let Django handle cascade
+print("Deleting parent (with cascade)...")
+with transaction.atomic():
+    # Delete parent and let Django handle cascade
+    parent.delete()  # This should now only fetch required fields
+
+# Print executed queries
+print("\nQueries executed:")
+for query in connection.queries:
+    print(f"\n{query['sql']}")
\ No newline at end of file
