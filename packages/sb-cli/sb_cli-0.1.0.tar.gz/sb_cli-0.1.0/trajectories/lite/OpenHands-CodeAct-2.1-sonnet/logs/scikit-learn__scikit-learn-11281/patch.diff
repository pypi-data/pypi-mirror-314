diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py
index a9f66740f..08840456b 100644
--- a/sklearn/mixture/base.py
+++ b/sklearn/mixture/base.py
@@ -190,6 +190,8 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):
         """
         X = _check_X(X, self.n_components, ensure_min_samples=2)
         self._check_initial_parameters(X)
+        # Store training data labels after fitting
+        self.labels_ = None
 
         # if we enable warm_start, we will have a unique initialisation
         do_init = not(self.warm_start and hasattr(self, 'converged_'))
@@ -340,6 +342,28 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):
         X = _check_X(X, None, self.means_.shape[1])
         return self._estimate_weighted_log_prob(X).argmax(axis=1)
 
+    def fit_predict(self, X, y=None):
+        """Fit the model and predict labels for X.
+
+        This is more efficient than calling fit followed by predict as it avoids
+        a second pass over the data.
+
+        Parameters
+        ----------
+        X : array-like, shape (n_samples, n_features)
+            List of n_features-dimensional data points. Each row
+            corresponds to a single data point.
+
+        Returns
+        -------
+        labels : array, shape (n_samples,)
+            Component labels.
+        """
+        self.fit(X)
+        # Store training data labels
+        self.labels_ = self.predict(X)
+        return self.labels_
+
     def predict_proba(self, X):
         """Predict posterior probability of each component given the data.
 
diff --git a/sklearn/mixture/gaussian_mixture.py b/sklearn/mixture/gaussian_mixture.py
index d58a9e326..a842aaf6f 100644
--- a/sklearn/mixture/gaussian_mixture.py
+++ b/sklearn/mixture/gaussian_mixture.py
@@ -8,6 +8,7 @@ import numpy as np
 
 from scipy import linalg
 
+import warnings
 from .base import BaseMixture, _check_shape
 from ..externals.six.moves import zip
 from ..utils import check_array
@@ -445,8 +446,12 @@ class GaussianMixture(BaseMixture):
 
     Parameters
     ----------
-    n_components : int, defaults to 1.
-        The number of mixture components.
+    n_clusters : int, defaults to 1.
+        The number of mixture components (clusters).
+        
+        .. versionchanged:: 0.20
+           Parameter ``n_components`` was renamed to ``n_clusters`` for consistency
+           with other clustering estimators.
 
     covariance_type : {'full', 'tied', 'diag', 'spherical'},
             defaults to 'full'.
@@ -580,13 +585,23 @@ class GaussianMixture(BaseMixture):
         inference.
     """
 
-    def __init__(self, n_components=1, covariance_type='full', tol=1e-3,
+    def __init__(self, n_clusters=None, covariance_type='full', tol=1e-3,
                  reg_covar=1e-6, max_iter=100, n_init=1, init_params='kmeans',
                  weights_init=None, means_init=None, precisions_init=None,
                  random_state=None, warm_start=False,
-                 verbose=0, verbose_interval=10):
+                 verbose=0, verbose_interval=10, n_components=None):
+        # For backward compatibility, allow both n_components and n_clusters
+        if n_clusters is None and n_components is None:
+            n_clusters = 1
+        elif n_clusters is not None and n_components is not None:
+            raise ValueError("Only one of n_clusters or n_components should be specified.")
+        elif n_clusters is None:
+            n_clusters = n_components
+            warnings.warn("Parameter n_components is deprecated and will be removed "
+                        "in version 0.21. Use n_clusters instead.", DeprecationWarning)
+        
         super(GaussianMixture, self).__init__(
-            n_components=n_components, tol=tol, reg_covar=reg_covar,
+            n_components=n_clusters, tol=tol, reg_covar=reg_covar,
             max_iter=max_iter, n_init=n_init, init_params=init_params,
             random_state=random_state, warm_start=warm_start,
             verbose=verbose, verbose_interval=verbose_interval)
diff --git a/test_mixture.py b/test_mixture.py
new file mode 100644
index 000000000..edd20e93d
--- /dev/null
+++ b/test_mixture.py
@@ -0,0 +1,21 @@
+from sklearn.mixture import GaussianMixture
+import numpy as np
+
+# Generate random data
+np.random.seed(42)
+X = np.concatenate([
+    np.random.normal(0, 1, (100, 2)),
+    np.random.normal(4, 1, (100, 2))
+])
+
+# Test with n_clusters parameter
+gm = GaussianMixture(n_clusters=2)
+labels = gm.fit_predict(X)
+print("fit_predict result:", labels[:10])  # Show first 10 labels
+print("labels_ attribute:", gm.labels_[:10])  # Should be the same as fit_predict
+
+# Test backward compatibility with n_components
+gm2 = GaussianMixture(n_components=2)
+labels2 = gm2.fit_predict(X)
+print("\nBackward compatibility test:")
+print("Using n_components, labels:", labels2[:10])
\ No newline at end of file
