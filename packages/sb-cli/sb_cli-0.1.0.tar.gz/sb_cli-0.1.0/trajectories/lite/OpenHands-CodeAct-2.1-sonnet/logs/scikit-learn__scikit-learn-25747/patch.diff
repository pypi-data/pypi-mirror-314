diff --git a/edge_case_test.py b/edge_case_test.py
new file mode 100644
index 000000000..62febe9d9
--- /dev/null
+++ b/edge_case_test.py
@@ -0,0 +1,50 @@
+import pandas as pd
+from typing import Optional
+from sklearn.base import BaseEstimator, TransformerMixin
+from sklearn import set_config
+from sklearn.pipeline import make_union
+
+index = pd.date_range(start="2020-01-01", end="2020-01-05", inclusive="left", freq="H")
+data = pd.DataFrame(index=index, data=[10] * len(index), columns=["value"])
+data["date"] = index.date
+
+
+class AggregatingTransformer(BaseEstimator, TransformerMixin):
+    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None, **kwargs):
+        return self
+
+    def transform(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> pd.DataFrame:
+        return X["value"].groupby(X["date"]).sum().to_frame("agg_value")
+
+
+class PassthroughTransformer(BaseEstimator, TransformerMixin):
+    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None, **kwargs):
+        return self
+
+    def transform(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> pd.DataFrame:
+        return X[["value"]].copy()
+
+
+class HalfAggregatingTransformer(BaseEstimator, TransformerMixin):
+    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None, **kwargs):
+        return self
+
+    def transform(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> pd.DataFrame:
+        # Group by date but keep 12-hour periods
+        X = X.copy()
+        X["hour"] = X.index.hour
+        return X.groupby([X["date"], X["hour"] >= 12])["value"].sum().to_frame("half_day_value")
+
+
+# Test with pandas output
+set_config(transform_output="pandas")
+union = make_union(
+    AggregatingTransformer(),
+    PassthroughTransformer(),
+    HalfAggregatingTransformer()
+)
+result = union.fit_transform(data)
+print("\nTesting with multiple transformers:")
+print("Shape:", result.shape)
+print("\nFirst few rows:")
+print(result.head())
\ No newline at end of file
diff --git a/reproduce_error.py b/reproduce_error.py
new file mode 100644
index 000000000..cddc6df71
--- /dev/null
+++ b/reproduce_error.py
@@ -0,0 +1,28 @@
+import pandas as pd
+from typing import Optional, Union
+from sklearn.base import BaseEstimator, TransformerMixin
+from sklearn import set_config
+from sklearn.pipeline import make_union
+
+index = pd.date_range(start="2020-01-01", end="2020-01-05", inclusive="left", freq="H")
+data = pd.DataFrame(index=index, data=[10] * len(index), columns=["value"])
+data["date"] = index.date
+
+
+class MyTransformer(BaseEstimator, TransformerMixin):
+    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None, **kwargs):
+        return self
+
+    def transform(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> pd.DataFrame:
+        return X["value"].groupby(X["date"]).sum()
+
+
+# This works.
+set_config(transform_output="default")
+print("Testing with default output:")
+print(make_union(MyTransformer()).fit_transform(data))
+
+# This does not work.
+set_config(transform_output="pandas")
+print("\nTesting with pandas output:")
+print(make_union(MyTransformer()).fit_transform(data))
\ No newline at end of file
diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py
index 94d9465d7..8a4a4df5e 100644
--- a/sklearn/pipeline.py
+++ b/sklearn/pipeline.py
@@ -1280,7 +1280,50 @@ class FeatureUnion(TransformerMixin, _BaseComposition):
         config = _get_output_config("transform", self)
         if config["dense"] == "pandas" and all(hasattr(X, "iloc") for X in Xs):
             pd = check_pandas_support("transform")
-            return pd.concat(Xs, axis=1)
+            
+            # Process each DataFrame to ensure unique column names and handle indices
+            Xs_with_names = list(zip(self._iter(), Xs))
+            processed_Xs = []
+            for (name, _, _), X in Xs_with_names:
+                # Convert to DataFrame if Series
+                if isinstance(X, pd.Series):
+                    X = X.to_frame()
+                
+                # If index is MultiIndex, convert to single index by joining names with __
+                if isinstance(X.index, pd.MultiIndex):
+                    X = X.copy()
+                    X.index = [
+                        "__".join(str(x) for x in idx_tuple)
+                        for idx_tuple in X.index
+                    ]
+                
+                # Add prefix to column names to ensure uniqueness
+                X = X.copy()
+                X.columns = [f"{name}__{col}" for col in X.columns]
+                processed_Xs.append(X)
+            
+            # If any transformer changes the number of rows, we need to handle each case
+            if len(set(X.shape[0] for X in processed_Xs)) > 1:
+                # For each transformer output, if it has fewer rows than the input
+                # we assume it's an aggregation and broadcast it to match other outputs
+                max_rows = max(X.shape[0] for X in processed_Xs)
+                processed_Xs = [
+                    (
+                        pd.concat([X] * (max_rows // X.shape[0]))
+                        if X.shape[0] < max_rows
+                        else X
+                    )
+                    for X in processed_Xs
+                ]
+            
+            # Ensure all DataFrames have same index
+            # Use range index for simplicity and consistency
+            for X in processed_Xs:
+                X.index = pd.RangeIndex(stop=len(X))
+            
+            # Concatenate horizontally
+            result = pd.concat(processed_Xs, axis=1)
+            return result
 
         if any(sparse.issparse(f) for f in Xs):
             Xs = sparse.hstack(Xs).tocsr()
diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py
index 335773c6a..2b154015c 100644
--- a/sklearn/utils/_set_output.py
+++ b/sklearn/utils/_set_output.py
@@ -55,11 +55,12 @@ def _wrap_in_pandas_container(
     if isinstance(data_to_wrap, pd.DataFrame):
         if columns is not None:
             data_to_wrap.columns = columns
-        if index is not None:
+        # Only set index if it matches the number of rows
+        if index is not None and len(index) == len(data_to_wrap):
             data_to_wrap.index = index
         return data_to_wrap
 
-    return pd.DataFrame(data_to_wrap, index=index, columns=columns)
+    return pd.DataFrame(data_to_wrap, index=index if index is not None and len(index) == len(data_to_wrap) else None, columns=columns)
 
 
 def _get_output_config(method, estimator=None):
