diff --git a/reproduce_error.py b/reproduce_error.py
new file mode 100644
index 000000000..8a4c981a7
--- /dev/null
+++ b/reproduce_error.py
@@ -0,0 +1,41 @@
+import numpy as np
+import pandas as pd
+from sklearn.compose import ColumnTransformer
+from sklearn.impute import SimpleImputer
+from sklearn.pipeline import Pipeline
+from sklearn.preprocessing import RobustScaler
+
+X = pd.DataFrame(data=[[1.0, 2.0, 3.0, 4.0], [4, 2, 2, 5]],
+                columns=["a", "b", "c", "d"])
+y = np.array([0, 1])
+categorical_features = []
+numerical_features = ["a", "b", "c"]
+model_preprocessing = ("preprocessing",
+                      ColumnTransformer([
+                          ('categorical', 'passthrough', categorical_features),
+                          ('numerical', Pipeline([("scaler", RobustScaler()),
+                                                ("imputer", SimpleImputer(strategy="median"))
+                                                ]), numerical_features),
+                      ], remainder='drop'))
+pipeline = Pipeline([model_preprocessing]).set_output(transform="pandas")
+
+# Add debug prints
+ct = pipeline.named_steps['preprocessing']
+print("Transformers:", ct.transformers)
+
+# Add debug prints to _fit_transform_one
+def _fit_transform_one_debug(transformer, X, y, weight, message_clsname="", message=""):
+    print(f"\nTransforming {transformer} with X shape {X.shape}")
+    if hasattr(transformer, "fit_transform"):
+        res = transformer.fit_transform(X, y)
+    else:
+        res = transformer.fit(X, y).transform(X)
+    print(f"Output shape: {res.shape}")
+    return res, transformer
+
+# Monkey patch the function
+from sklearn.pipeline import _fit_transform_one
+import types
+_fit_transform_one.__code__ = _fit_transform_one_debug.__code__
+
+pipeline.fit(X, y)
\ No newline at end of file
diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py
index a26145117..ece166952 100644
--- a/sklearn/compose/_column_transformer.py
+++ b/sklearn/compose/_column_transformer.py
@@ -862,12 +862,31 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):
                 if not self.verbose_feature_names_out:
                     return output
 
-                transformer_names = [
-                    t[0] for t in self._iter(fitted=True, replace_strings=True)
-                ]
-                feature_names_outs = [X.columns for X in Xs]
+                # Get all transformer names and their indices
+                transformer_names = []
+                valid_indices = []
+                print("Xs:", [X.shape for X in Xs])
+                
+                # First pass: collect valid transformers and their indices
+                output_idx = 0
+                transformer_feature_names = []
+                for idx, (name, trans, columns, _) in enumerate(self._iter(fitted=True, replace_strings=True)):
+                    print(f"Transformer {idx}: name={name}, trans={trans}, columns={columns}")
+                    if not (isinstance(trans, str) and trans == "drop") and not _is_empty_column_selection(columns):
+                        transformer_names.append(name)
+                        # Get the output from the correct transformer
+                        for X in Xs:
+                            if X.shape[1] == len(columns):
+                                transformer_feature_names.append(X.columns)
+                                break
+                        output_idx += 1
+                
+                print("Transformer names:", transformer_names)
+                print("Feature names:", transformer_feature_names)
+                
+                # Match transformer names with their feature names
                 names_out = self._add_prefix_for_feature_names_out(
-                    list(zip(transformer_names, feature_names_outs))
+                    list(zip(transformer_names, transformer_feature_names))
                 )
                 output.columns = names_out
                 return output
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 000000000..97da1da59
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,48 @@
+import numpy as np
+import pandas as pd
+from sklearn.compose import ColumnTransformer
+from sklearn.impute import SimpleImputer
+from sklearn.pipeline import Pipeline
+from sklearn.preprocessing import RobustScaler
+
+# Test case 1: Multiple empty transformers
+X = pd.DataFrame(data=[[1.0, 2.0, 3.0, 4.0], [4, 2, 2, 5]],
+                columns=["a", "b", "c", "d"])
+y = np.array([0, 1])
+ct = ColumnTransformer([
+    ('empty1', 'passthrough', []),
+    ('numerical', Pipeline([("scaler", RobustScaler())]), ["a", "b"]),
+    ('empty2', 'passthrough', []),
+    ('numerical2', Pipeline([("imputer", SimpleImputer())]), ["c"]),
+], remainder='drop').set_output(transform="pandas")
+print("\nTest case 1:")
+result = ct.fit_transform(X, y)
+print("Result shape:", result.shape)
+print("Result columns:", result.columns)
+
+# Test case 2: All empty transformers
+X = pd.DataFrame(data=[[1.0, 2.0, 3.0, 4.0], [4, 2, 2, 5]],
+                columns=["a", "b", "c", "d"])
+y = np.array([0, 1])
+ct = ColumnTransformer([
+    ('empty1', 'passthrough', []),
+    ('empty2', 'passthrough', []),
+], remainder='drop').set_output(transform="pandas")
+print("\nTest case 2:")
+result = ct.fit_transform(X, y)
+print("Result shape:", result.shape)
+print("Result columns:", result.columns)
+
+# Test case 3: Mix of empty, drop and passthrough
+X = pd.DataFrame(data=[[1.0, 2.0, 3.0, 4.0], [4, 2, 2, 5]],
+                columns=["a", "b", "c", "d"])
+y = np.array([0, 1])
+ct = ColumnTransformer([
+    ('empty1', 'passthrough', []),
+    ('drop1', 'drop', ["a"]),
+    ('numerical', Pipeline([("scaler", RobustScaler())]), ["b", "c"]),
+], remainder='passthrough').set_output(transform="pandas")
+print("\nTest case 3:")
+result = ct.fit_transform(X, y)
+print("Result shape:", result.shape)
+print("Result columns:", result.columns)
\ No newline at end of file
