diff --git a/edge_cases.py b/edge_cases.py
new file mode 100644
index 0000000000..8d64874c54
--- /dev/null
+++ b/edge_cases.py
@@ -0,0 +1,27 @@
+from sympy.parsing.mathematica import parse_mathematica
+
+# Test various Unicode characters
+test_cases = [
+    'λ',  # Greek lowercase lambda
+    'Λ',  # Greek uppercase lambda
+    'α',  # Greek lowercase alpha
+    'β',  # Greek lowercase beta
+    'π',  # Greek lowercase pi
+    'Π',  # Greek uppercase pi
+    'μ',  # Greek lowercase mu
+    'ω',  # Greek lowercase omega
+    'Ω',  # Greek uppercase omega
+    'λ[x]',  # Greek letter as function name
+    'Sin[λ]',  # Greek letter as argument
+    'λ + β',  # Greek letters in expression
+    'λ[α, β]',  # Multiple Greek letters
+]
+
+print("Testing edge cases:")
+for case in test_cases:
+    print(f"\nTesting: {case}")
+    try:
+        result = parse_mathematica(case)
+        print(f"Success: {result}")
+    except Exception as e:
+        print(f"Error: {e}")
\ No newline at end of file
diff --git a/reproduce.py b/reproduce.py
new file mode 100644
index 0000000000..0f0fe4671d
--- /dev/null
+++ b/reproduce.py
@@ -0,0 +1,18 @@
+from sympy.parsing.mathematica import parse_mathematica
+
+# Test the old parser (should work)
+from sympy.parsing.mathematica import mathematica
+print("Testing old parser (mathematica):")
+try:
+    result = mathematica('λ')
+    print(f"Success: {result}")
+except Exception as e:
+    print(f"Error: {e}")
+
+# Test the new parser (should fail)
+print("\nTesting new parser (parse_mathematica):")
+try:
+    result = parse_mathematica('λ')
+    print(f"Success: {result}")
+except Exception as e:
+    print(f"Error: {e}")
\ No newline at end of file
diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py
index 7ea14ce33a..92db907873 100644
--- a/sympy/parsing/mathematica.py
+++ b/sympy/parsing/mathematica.py
@@ -586,7 +586,7 @@ def parse(self, s):
         "##": lambda: ["SlotSequence", "1"],
     }
 
-    _literal = r"[A-Za-z][A-Za-z0-9]*"
+    _literal = r"[^\W\d_][^\W\d_0-9]*"
     _number = r"(?:[0-9]+(?:\.[0-9]*)?|\.[0-9]+)"
 
     _enclosure_open = ["(", "[", "[[", "{"]
@@ -615,7 +615,7 @@ def _get_tokenizer(self):
         tokens.extend(map(re.escape, tokens_escape))
         tokens.append(",")
         tokens.append("\n")
-        tokenizer = re.compile("(" + "|".join(tokens) + ")")
+        tokenizer = re.compile("(" + "|".join(tokens) + ")", re.UNICODE)
         self._regex_tokenizer = tokenizer
         return self._regex_tokenizer
