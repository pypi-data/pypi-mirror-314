diff --git a/reproduce.py b/reproduce.py
new file mode 100644
index 00000000..5a0bc23c
--- /dev/null
+++ b/reproduce.py
@@ -0,0 +1,22 @@
+import numpy as np
+import xarray as xr
+import dask.array as da
+
+# Test case 1: From the first example
+foo = xr.DataArray(np.random.randn(3, 3), dims=("x", "y")).chunk()
+ds = xr.Dataset({"foo": foo, "bar": ("x", [1, 2, 3])})
+print("Initial foo data type:", type(ds.foo.data))
+
+update_dict = {"foo": (("x", "y"), ds.foo[1:, :]), "bar": ("x", ds.bar[1:])}
+print("Update dict foo data type:", type(update_dict["foo"][1].data))
+
+ds.update(update_dict)
+print("After update foo data type:", type(ds.foo.data))
+
+# Test case 2: From the second example
+x = da.random.randint(1, 10, size=(100, 25))
+ds = xr.Dataset(dict(a=xr.DataArray(x, dims=('x', 'y'))))
+print("\nTest case 2 - Initial a data type:", type(ds.a.data))
+
+ds2 = xr.Dataset(dict(a=(('x', 'y'), ds.a)))
+print("Test case 2 - After recreation data type:", type(ds2.a.data))
\ No newline at end of file
diff --git a/xarray/core/merge.py b/xarray/core/merge.py
index d29a9e1f..05eacd4f 100644
--- a/xarray/core/merge.py
+++ b/xarray/core/merge.py
@@ -117,7 +117,21 @@ def unique_variable(
 
     if compat == "broadcast_equals":
         dim_lengths = broadcast_dimension_size(variables)
-        out = out.set_dims(dim_lengths)
+        # Preserve chunking information when broadcasting
+        if hasattr(out.data, "chunks") and out.data.chunks is not None:
+            out = out.set_dims(dim_lengths, preserve_chunks=True)
+        else:
+            # Check if any of the other variables have chunks we should preserve
+            for var in variables[1:]:
+                if hasattr(var.data, "chunks") and var.data.chunks is not None:
+                    # Convert out to chunked array with same chunking as var
+                    import dask.array as da
+                    out_data = da.from_array(out.data, chunks=var.data.chunks)
+                    out = Variable(out.dims, out_data, out.attrs, out.encoding)
+                    out = out.set_dims(dim_lengths, preserve_chunks=True)
+                    break
+            else:
+                out = out.set_dims(dim_lengths)
 
     if compat == "no_conflicts":
         combine_method = "fillna"
diff --git a/xarray/core/variable.py b/xarray/core/variable.py
index 64c1895d..3e5ef9eb 100644
--- a/xarray/core/variable.py
+++ b/xarray/core/variable.py
@@ -121,7 +121,14 @@ def as_variable(obj, name=None) -> "Union[Variable, IndexVariable]":
         obj = obj.copy(deep=False)
     elif isinstance(obj, tuple):
         try:
-            obj = Variable(*obj)
+            # Check if we're dealing with a tuple that contains a chunked array
+            if len(obj) >= 2 and hasattr(obj[1], "chunks") and obj[1].chunks is not None:
+                dims, data = obj[:2]
+                attrs = obj[2] if len(obj) >= 3 else None
+                encoding = obj[3] if len(obj) >= 4 else None
+                obj = Variable(dims, data, attrs, encoding)
+            else:
+                obj = Variable(*obj)
         except (TypeError, ValueError) as error:
             # use .format() instead of % because it handles tuples consistently
             raise error.__class__(
@@ -218,7 +225,13 @@ def as_compatible_data(data, fastpath=False):
         data = np.timedelta64(getattr(data, "value", data), "ns")
 
     # we don't want nested self-described arrays
+    original_data = data
     data = getattr(data, "values", data)
+    # Preserve chunking if the original data had it
+    if hasattr(original_data, "chunks") and original_data.chunks is not None:
+        import dask.array as da
+        if isinstance(data, np.ndarray):
+            data = da.from_array(data, chunks=original_data.chunks)
 
     if isinstance(data, np.ma.MaskedArray):
         mask = np.ma.getmaskarray(data)
@@ -1440,7 +1453,7 @@ class Variable(
     def T(self) -> "Variable":
         return self.transpose()
 
-    def set_dims(self, dims, shape=None):
+    def set_dims(self, dims, shape=None, preserve_chunks=False):
         """Return a new variable with given set of dimensions.
         This method might be used to attach new dimension(s) to variable.
 
@@ -1452,6 +1465,11 @@ class Variable(
             Dimensions to include on the new variable. If a dict, values are
             used to provide the sizes of new dimensions; otherwise, new
             dimensions are inserted with length 1.
+        shape : tuple, optional
+            Shape to reshape the data to. If not provided, inferred from dims.
+        preserve_chunks : bool, optional
+            If True and the variable has dask chunks, preserve them when reshaping.
+            Default is False.
 
         Returns
         -------
@@ -1480,9 +1498,24 @@ class Variable(
         elif shape is not None:
             dims_map = dict(zip(dims, shape))
             tmp_shape = tuple(dims_map[d] for d in expanded_dims)
-            expanded_data = duck_array_ops.broadcast_to(self.data, tmp_shape)
+            if preserve_chunks and hasattr(self.data, "chunks") and self.data.chunks is not None:
+                # For dask arrays, preserve chunking when broadcasting
+                import dask.array as da
+                # Create chunks for new dimensions as single chunks
+                new_chunks = tuple(
+                    (s,) if d not in self.dims else self.data.chunks[self.dims.index(d)]
+                    for d, s in zip(expanded_dims, tmp_shape)
+                )
+                expanded_data = da.broadcast_to(self.data, tmp_shape, chunks=new_chunks)
+            else:
+                expanded_data = duck_array_ops.broadcast_to(self.data, tmp_shape)
         else:
-            expanded_data = self.data[(None,) * (len(expanded_dims) - self.ndim)]
+            if preserve_chunks and hasattr(self.data, "chunks") and self.data.chunks is not None:
+                # For dask arrays, preserve chunking when adding new dimensions
+                import dask.array as da
+                expanded_data = da.reshape(self.data, (1,) * (len(expanded_dims) - self.ndim) + self.shape)
+            else:
+                expanded_data = self.data[(None,) * (len(expanded_dims) - self.ndim)]
 
         expanded_var = Variable(
             expanded_dims, expanded_data, self._attrs, self._encoding, fastpath=True
