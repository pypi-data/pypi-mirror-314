import scrapy
from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor
from gzspidertools.items import AyuItem
from gzspidertools.spiders import AyuCrawlSpider


class $classname(AyuCrawlSpider):
    name = "$name"
    allowed_domains = ["$domain"]
    start_urls = ["http://$domain/"]
    custom_settings = {
        "ITEM_PIPELINES": {
            "gzspidertools.pipelines.AyuFtyMysqlPipeline": 300,
        },
        "DOWNLOADER_MIDDLEWARES": {
            "gzspidertools.middlewares.RandomRequestUaMiddleware": 400,
        },
    }

    rules = (
        # Rule(LinkExtractor(allow=r"Items/"), callback="parse_item", follow=True),
        Rule(LinkExtractor(restrict_xpaths='//div[@class="rank_d_b_name"]/a'), callback="parse_item"),
    )

    def parse_item(self, response):
        # 获取图书名称 - （获取的是详情页中的图书名称）
        book_name_list = response.xpath('//div[@class="book-name"]//text()').extract()
        book_name = "".join(book_name_list).strip()
        self.slog.debug(f"book_name: {book_name}")

        NovelInfoItem = AyuItem(
            book_name=book_name,
            _table="_article_info_list",
        )
        yield NovelInfoItem
