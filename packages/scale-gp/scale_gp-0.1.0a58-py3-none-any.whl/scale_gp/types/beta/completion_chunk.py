# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from typing import TYPE_CHECKING, List, Union, Optional
from typing_extensions import TypeAlias

from ..._models import BaseModel

__all__ = [
    "CompletionChunk",
    "Choice",
    "ChoiceLogprobs",
    "ChoiceLogprobsContent",
    "ChoiceLogprobsContentTopLogprob",
    "Error",
    "Usage",
    "UsageCompletionTokensDetails",
    "UsageCompletionTokensDetailsCompletionTokensDetailsWrapper",
    "UsagePromptTokensDetails",
    "UsagePromptTokensDetailsPromptTokensDetailsWrapper",
]


class ChoiceLogprobsContentTopLogprob(BaseModel):
    token: str

    logprob: float

    bytes: Optional[List[int]] = None


class ChoiceLogprobsContent(BaseModel):
    token: str

    logprob: float

    top_logprobs: List[ChoiceLogprobsContentTopLogprob]

    bytes: Optional[List[int]] = None


class ChoiceLogprobs(BaseModel):
    content: Optional[List[ChoiceLogprobsContent]] = None
    """A list of message content tokens with log probability information."""

    refusal: Optional[List[str]] = None
    """A list of message refusal tokens with log probability information."""


class Choice(BaseModel):
    finish_reason: Optional[str] = None
    """The reason the completion stopped.

    This field is only present if the completion stopped early.
    """

    index: Optional[int] = None
    """The index of the completion choice."""

    logprobs: Optional[ChoiceLogprobs] = None
    """Log probabilities of the tokens generated."""

    text: Optional[str] = None
    """Text generated by the model."""


class Error(BaseModel):
    message: str

    status_code: int


class UsageCompletionTokensDetailsCompletionTokensDetailsWrapper(BaseModel):
    accepted_prediction_tokens: Optional[int] = None

    audio_tokens: Optional[int] = None

    reasoning_tokens: Optional[int] = None

    rejected_prediction_tokens: Optional[int] = None

    text_tokens: Optional[int] = None

    if TYPE_CHECKING:
        # Stub to indicate that arbitrary properties are accepted.
        # To access properties that are not valid identifiers you can use `getattr`, e.g.
        # `getattr(obj, '$type')`
        def __getattr__(self, attr: str) -> object: ...


UsageCompletionTokensDetails: TypeAlias = Union[UsageCompletionTokensDetailsCompletionTokensDetailsWrapper, object]


class UsagePromptTokensDetailsPromptTokensDetailsWrapper(BaseModel):
    audio_tokens: Optional[int] = None

    cached_tokens: Optional[int] = None

    image_tokens: Optional[int] = None

    text_tokens: Optional[int] = None

    if TYPE_CHECKING:
        # Stub to indicate that arbitrary properties are accepted.
        # To access properties that are not valid identifiers you can use `getattr`, e.g.
        # `getattr(obj, '$type')`
        def __getattr__(self, attr: str) -> object: ...


UsagePromptTokensDetails: TypeAlias = Union[UsagePromptTokensDetailsPromptTokensDetailsWrapper, object]


class Usage(BaseModel):
    completion_tokens: Optional[int] = None
    """The number of tokens in the output completion."""

    completion_tokens_details: Optional[UsageCompletionTokensDetails] = None
    """Breakdown of tokens used in the prompt."""

    prompt_tokens: Optional[int] = None
    """The number of tokens in the generated completion."""

    prompt_tokens_details: Optional[UsagePromptTokensDetails] = None
    """Breakdown of tokens used in a completion."""

    total_tokens: Optional[int] = None
    """The total number of tokens in the prompt and completion."""


class CompletionChunk(BaseModel):
    choices: List[Choice]
    """The list of completions."""

    id: Optional[str] = None
    """A unique identifier for the completion."""

    chunk_type: Optional[str] = None

    created: Optional[int] = None
    """The Unix timestamp (in seconds) of when the chat completion was created."""

    error: Optional[Error] = None

    model: Optional[str] = None
    """The model used for completion."""

    object: Optional[str] = None
    """The object type, ex `text_completion` or `chat.completion`"""

    system_fingerprint: Optional[str] = None
    """This fingerprint represents the backend configuration that the model runs with."""

    usage: Optional[Usage] = None
    """Usage statistics."""
