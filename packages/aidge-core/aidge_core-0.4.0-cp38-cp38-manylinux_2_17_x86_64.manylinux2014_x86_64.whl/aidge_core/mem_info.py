import os
import subprocess
import shutil
from pathlib import Path
import aidge_core
from typing import Tuple, List


# Default memory management, which can be used for development
def compute_default_mem_info(scheduler: aidge_core.Scheduler) -> Tuple[int, List]:
    """Basic memory management concatenate memory block, no memory reuse !

    :param scheduler: Aidge scheduler
    :type scheduler: :py:class:`aidge_core.Scheduler`
    :return: The total memory size (in number of elements) and a list (of size nb node) of list (of size nb output) of dictionnary (size, offset)
    :rtype: Tuple[int, list]
    """
    mem_info = {}
    mem_size = 0

    # Exclude Producers and the last layers (because the results are stored outside the export)
    for i, node in enumerate(scheduler.get_static_scheduling()):
        if node.type() != "Producer":
            node_mem_info = []
            for out_id in range(node.get_nb_outputs()):
                dims = node.get_operator().get_output(out_id).dims()
                mem = 1
                for dim in dims:
                    mem *= dim

                # Add memeory info
                node_mem_info.append({
                    "size": mem,
                    "offset": mem_size
                })

                # Increment offset for the next layer
                mem_size += mem
            mem_info[node] = node_mem_info
        else:
            mem_info[node] = [] # No meminfo for producer
    return mem_size, mem_info


def _gnuplot_installed():
    try:
        # Run gnuplot with the --version flag and capture the output
        subprocess.run(["gnuplot", "--version"])
        return True
    except FileNotFoundError:
        aidge_core.Log.warn("Gnuplot is not installed.")
        return False
    except subprocess.CalledProcessError:
        aidge_core.Log.warn("Gnuplot command found but failed to run.")
        return False

def generate_optimized_memory_info(scheduler: aidge_core.Scheduler, stats_folder: Path = None, wrapping: bool = False) -> Tuple[int, List[dict]]:
    """Generates optimized memory information for a computation graph managed by a scheduler.

    This function analyzes the memory usage of a computation graph, determining the memory peak
    and detailed memory management information for each node in the scheduler. It supports optional
    wrapping of memory buffers and logs memory usage statistics to facilitate memory optimization.

    :param scheduler: Scheduler instance that organizes the computation graph. It manages the
                      nodes and facilitates memory planning by invoking its `generate_memory` method.
    :type scheduler: aidge_core.Scheduler
    :param stats_folder: Directory path to store memory statistics and plots generated by `mem_manager`.
                         If provided as a string, it is converted to a `Path` object, default=None.
    :type stats_folder: Path, optional
    :param wrapping: Boolean flag to enable or disable wrap-around buffer optimization.
                     Defaults to `False`.
    :type wrapping: bool, optional
    :return: A tuple containing the peak memory size and a list of memory information for each
             scheduled node. The memory information for each node includes details such as size,
             offset, stride, length, count, and optional wrap-around details.
    :rtype: Tuple[int, List[dict]]
    """
    # The forward dims has to done outside the function
    # Also supposed the generation of the scheduler has been performed outside
    # Otherwise decomment the following line
    # scheduler.generate_scheduling()
    # Generate the memory manager
    # So far, the Producers are not take in consideration in the meory manager => inc_producers=False
    mem_manager = scheduler.generate_memory(
        inc_producers=False, wrap_around_buffer=wrapping)

    # List of nodes which are connected at the input of the graph (None if input is not connected)
    nodes_at_input = [n[0] for n in scheduler.graph_view().inputs()]

    if stats_folder is not None:
        if _gnuplot_installed():
            # Use gnuplot to generate the log
            os.makedirs(str(Path(stats_folder) / "graph"), exist_ok=True)
            mem_manager.log("memory_info")
            os.chmod("memory_info_plot.gnu", 0o777)
            os.system("./memory_info_plot.gnu")
            shutil.move("memory_info", str(Path(stats_folder) / "graph" / "memory_info"))
            shutil.move("memory_info_plot.png", str(
                Path(stats_folder) / "graph" / "memory_info_plot.png"))
            os.remove("memory_info_plot.gnu")
        else:
            aidge_core.Log.warn("Warning: gnuplot is not installed, could not generate stat folder.")
    # In the export, we currently use an unified memory buffer whose size
    # is determined by the memory peak usage
    mem_size = mem_manager.get_peak_usage()
    mem_info = {}

    mem_planes = mem_manager.get_planes()

    for node in scheduler.get_static_scheduling():
        node_mem_info = []
        if node.type() == "Producer":
            pass
        elif node in nodes_at_input:
            # Input memory management (suppose tensor ends with [:, channel, height, width]))
            tensor = node.get_operator().get_output(0)
            if tensor is None:
                raise RuntimeError("Warning input producer not provided")
            if len(tensor.dims()) < 3:
                raise RuntimeError(
                    f"Input producer dimensions must be with [:, channel, height, width] but got {tensor.dims()} instead")
            # TODO : use get_chan get_height and get_width function !
            node_mem_info.append({
                    "size": tensor.dims()[-3],          # Should be nb_channels
                    "offset": 0,                        # Suppose input data is stored outside the export function
                                                        # so the memory offset is not important to consider
                    "stride": tensor.dims()[-3],        # Should be nb_channels
                    "length": tensor.dims()[-1],        # Should be width
                    "count":  tensor.dims()[-2],        # Should be height
                    "cont_offset": 0,                   # Suppose input data is stored outside the export function
                                                        # so the memory offset is not important to consider
                    "cont_size": tensor.dims()[-1] * \
                                 tensor.dims()[-2] * \
                                 tensor.dims()[-3],     # Size of input
                    "wrap_offset": 0,                   # No wrapping
                    "wrap_size": 0                      # No wrapping
                })
        else:
            for out_id in range(node.get_nb_outputs()):
                plane = mem_planes[node][out_id]
                node_mem_info.append({
                    "size": plane.size,
                    "offset": plane.get_contiguous_offset(),
                    "stride": plane.stride,
                    "length": plane.length,
                    "count": plane.count,
                    "cont_offset": plane.get_contiguous_offset(),
                    "cont_size": plane.get_contiguous_size(),
                    "wrap_offset": plane.get_wrapped_offset(),
                    "wrap_size": plane.get_wrapped_size()
                })
        mem_info[node] = node_mem_info
    return mem_size, mem_info


